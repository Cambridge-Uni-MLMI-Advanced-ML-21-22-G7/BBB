{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bbb.utils.pytorch_setup import DEVICE\n",
    "from bbb.utils.plotting import plot_weight_samples\n",
    "from bbb.config.constants import KL_REWEIGHTING_TYPES, PRIOR_TYPES, VP_VARIANCE_TYPES\n",
    "from bbb.config.parameters import Parameters, PriorParameters\n",
    "from bbb.models.dnn import ClassificationDNN\n",
    "from bbb.models.bnn import ClassificationBNN\n",
    "from bbb.data import load_mnist\n",
    "from bbb.models.layers import BFC, BFC_LRT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelDetails = namedtuple('ModelDetails', 'dir mclass')\n",
    "\n",
    "MODEL_DETAILS_DICT = {\n",
    "    # BNN\n",
    "    \"bnn_1200\": ModelDetails(\"../saved_models/BBB_classification/2022-03-15-09.18.07\", ClassificationBNN),\n",
    "    \"bnn_800\": ModelDetails(\"../saved_models/BBB_classification/2022-03-15-14.25.46\", ClassificationBNN),\n",
    "    \"bnn_400\": ModelDetails(\"../saved_models/BBB_classification/2022-03-15-14.26.34\", ClassificationBNN),\n",
    "    # DNN - no dropout\n",
    "    \"dnn_1200\": ModelDetails(\"../saved_models/DNN_classification/2022-03-15-14.28.25\", ClassificationDNN),\n",
    "    \"dnn_800\": ModelDetails(\"../saved_models/DNN_classification/2022-03-15-16.06.09\", ClassificationDNN),\n",
    "    \"dnn_400\": ModelDetails(\"../saved_models/DNN_classification/2022-03-15-16.10.34\", ClassificationDNN),\n",
    "    # DNN - dropout\n",
    "    \"dnn_do_400\": ModelDetails(\"../saved_models/DNN_classification/2022-03-15-15.21.46\", ClassificationDNN),\n",
    "    \"dnn_do_800\": ModelDetails(\"../saved_models/DNN_classification/2022-03-15-15.58.04\", ClassificationDNN),\n",
    "    \"dnn_do_1200\": ModelDetails(\"../saved_models/DNN_classification/2022-03-15-16.26.18\", ClassificationDNN),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 00:27:02,182 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,182 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,193 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,193 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,195 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,195 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,215 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,215 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,220 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,220 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,221 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,222 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,234 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,235 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,238 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,238 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,238 - bbb.models.layers - INFO - Weights Prior: Gaussian with mean 0 and variance 1.0\n",
      "2022-03-16 00:27:02,239 - bbb.models.layers - INFO - Biases Prior: Gaussian with mean 0 and variance 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bnn_1200\n",
      "bnn_1200: -0.0010805814526975155 \t 0.022610129788517952\n",
      "bnn_1200: 0.0005043221171945333 \t 0.02260366827249527\n",
      "bnn_1200: -0.0022730641067028046 \t 0.022348301485180855\n",
      "Loading bnn_800\n",
      "bnn_800: -0.00013174352352507412 \t 0.01478757243603468\n",
      "bnn_800: 0.000435502064647153 \t 0.014787760563194752\n",
      "bnn_800: -0.0034469771198928356 \t 0.014695613645017147\n",
      "Loading bnn_400\n",
      "bnn_400: -0.000349174631992355 \t 0.018243536353111267\n",
      "bnn_400: 0.0024643607903271914 \t 0.01825784333050251\n",
      "bnn_400: -0.01089491881430149 \t 0.017943862825632095\n",
      "Loading dnn_1200\n",
      "Loading dnn_800\n",
      "Loading dnn_400\n",
      "Loading dnn_do_400\n",
      "Loading dnn_do_800\n",
      "Loading dnn_do_1200\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for MODEL in MODEL_DETAILS_DICT.keys():\n",
    "    print(\"Loading {}\".format(MODEL))\n",
    "    results_dict[MODEL] = {}\n",
    "\n",
    "    MODEL_DETAILS = MODEL_DETAILS_DICT[MODEL]\n",
    "\n",
    "    # Load parameters\n",
    "    with open(os.path.join(MODEL_DETAILS.dir, 'params.txt'), 'r') as f:\n",
    "        params_dict = json.load(f)\n",
    "\n",
    "    # Need to deserialise the prior_params into a PriorParameters object\n",
    "    if params_dict['prior_params']:\n",
    "        params_dict['prior_params'] = PriorParameters(**params_dict['prior_params'])\n",
    "\n",
    "    params = Parameters(**params_dict)\n",
    "\n",
    "    # Load model\n",
    "    net = MODEL_DETAILS.mclass(params=params, eval_mode=True) # .to(DEVICE) \n",
    "    net.model.load_state_dict(torch.load(os.path.join(MODEL_DETAILS.dir, 'model.pt'), map_location=torch.device('cpu')))\n",
    "\n",
    "    # Load evaluation metric results across epochs (list)\n",
    "    eval_metric = np.load(os.path.join(MODEL_DETAILS.dir, 'eval_metric.npy'))\n",
    "\n",
    "    # Add last epoch value\n",
    "    results_dict[MODEL]['eval_metric'] = eval_metric[-1]\n",
    "\n",
    "    weight_tensors = []\n",
    "    for layer in [l for l in net.model if isinstance(l, BFC)]:\n",
    "\n",
    "        # Average weight mean in layer, average weight variance in layer\n",
    "        mu = layer.w_var_post.mu.cpu().detach().numpy()\n",
    "        sigma = torch.log1p(torch.exp(layer.w_var_post.rho)).cpu().detach().numpy()\n",
    "        \n",
    "        print(\"{}: {} \\t {}\".format(MODEL, np.mean(mu), np.mean(sigma)))\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bnn_1200': {'eval_metric': 0.9863781929016113},\n",
       " 'bnn_800': {'eval_metric': 0.9849759936332703},\n",
       " 'bnn_400': {'eval_metric': 0.9855769276618958},\n",
       " 'dnn_1200': {'eval_metric': 0.9833734035491943},\n",
       " 'dnn_800': {'eval_metric': 0.9831730723381042},\n",
       " 'dnn_400': {'eval_metric': 0.9795673489570618},\n",
       " 'dnn_do_400': {'eval_metric': 0.9866787195205688},\n",
       " 'dnn_do_800': {'eval_metric': 0.9858773946762085},\n",
       " 'dnn_do_1200': {'eval_metric': 0.9847756624221802}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error\n",
      "bnn_1200: 1.362\n",
      "bnn_800: 1.502\n",
      "bnn_400: 1.442\n",
      "dnn_1200: 1.663\n",
      "dnn_800: 1.683\n",
      "dnn_400: 2.043\n",
      "dnn_do_400: 1.332\n",
      "dnn_do_800: 1.412\n",
      "dnn_do_1200: 1.522\n"
     ]
    }
   ],
   "source": [
    "print(\"Test error\")\n",
    "for model, results in results_dict.items():\n",
    "    print(\"{}: {}\".format(model, np.round(100*(1-results['eval_metric']), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5270afc4e1f7b529d51c14a6012429c52c3dbf5c86ddd8dcac8bfb87e34d88eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
